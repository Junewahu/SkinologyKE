{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0ba403",
   "metadata": {},
   "source": [
    "# SkinologyKE MobileNetV2 Training Notebook\n",
    "This notebook trains a lightweight skin condition classifier using MobileNetV2. Datasets: HAM10000, SD-260, Fitzpatrick17k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f906148e",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "Install TensorFlow, pandas, scikit-learn, and other required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f76fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow pandas scikit-learn matplotlib pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f3d3e5",
   "metadata": {},
   "source": [
    "## 2. Load Datasets\n",
    "Download and load HAM10000, SD-260, and Fitzpatrick17k datasets. (Use sample code for HAM10000; adapt for others.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7bda36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Example: Load HAM10000 metadata\n",
    "ham_meta = pd.read_csv('HAM10000_metadata.csv')\n",
    "image_dir = 'HAM10000_images/'\n",
    "image_paths = glob(os.path.join(image_dir, '*.jpg'))\n",
    "\n",
    "# Display sample\n",
    "ham_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21c0977",
   "metadata": {},
   "source": [
    "## 2a. Load SD-260 Dataset\n",
    "Download and load SD-260 metadata and images. Adjust paths as needed for your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d76fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load SD-260 metadata\n",
    "sd260_meta = pd.read_csv('SD-260_metadata.csv')\n",
    "sd260_image_dir = 'SD-260_images/'\n",
    "sd260_meta['img_path'] = sd260_meta['image_id'].apply(lambda x: os.path.join(sd260_image_dir, f'{x}.jpg'))\n",
    "# Display sample\n",
    "sd260_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9935da40",
   "metadata": {},
   "source": [
    "## 2b. Load Fitzpatrick17k Dataset\n",
    "Download and load Fitzpatrick17k metadata and images. Adjust paths as needed for your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190cd6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load Fitzpatrick17k metadata\n",
    "fitz_meta = pd.read_csv('Fitzpatrick17k_metadata.csv')\n",
    "fitz_image_dir = 'Fitzpatrick17k_images/'\n",
    "fitz_meta['img_path'] = fitz_meta['image_id'].apply(lambda x: os.path.join(fitz_image_dir, f'{x}.jpg'))\n",
    "# Display sample\n",
    "fitz_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40418715",
   "metadata": {},
   "source": [
    "## 3. Preprocess Images and Labels\n",
    "Resize images, normalize, and encode labels. Combine datasets if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5507dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "IMG_SIZE = 224\n",
    "\n",
    "def load_and_preprocess(img_path):\n",
    "    img = Image.open(img_path).resize((IMG_SIZE, IMG_SIZE))\n",
    "    arr = np.array(img) / 255.0\n",
    "    if arr.shape[-1] == 4:\n",
    "        arr = arr[..., :3]\n",
    "    return arr\n",
    "\n",
    "# Example: preprocess HAM10000\n",
    "ham_meta['img_path'] = ham_meta['image_id'].apply(lambda x: os.path.join(image_dir, f'{x}.jpg'))\n",
    "X = np.stack([load_and_preprocess(p) for p in ham_meta['img_path']])\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(ham_meta['dx'])\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "print('y shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce463643",
   "metadata": {},
   "source": [
    "## 3a. Advanced Data Augmentation\n",
    "Apply random flips, rotations, and color jitter to improve generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457a2094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "# Example: datagen.flow(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba60152",
   "metadata": {},
   "source": [
    "## 3b. Class Balancing and Multi-Dataset Merging\n",
    "Combine all datasets and balance classes for robust training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b52b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all datasets\n",
    "all_meta = pd.concat([ham_meta, sd260_meta, fitz_meta], ignore_index=True)\n",
    "all_X = np.stack([load_and_preprocess(p) for p in all_meta['img_path']])\n",
    "all_y = le.fit_transform(all_meta['dx'])\n",
    "\n",
    "# Class balancing (undersample/oversample example)\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "all_X_rs, all_y_rs = ros.fit_resample(all_X.reshape((all_X.shape[0], -1)), all_y)\n",
    "all_X_rs = all_X_rs.reshape((-1, IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "print('Balanced class distribution:', Counter(all_y_rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2582e1a3",
   "metadata": {},
   "source": [
    "## 3c. Save Label Mappings to labels.json\n",
    "Export label encoder classes for downstream inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a806848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "label_map = {str(i): c for i, c in enumerate(le.classes_)}\n",
    "with open('labels.json', 'w') as f:\n",
    "    json.dump(label_map, f)\n",
    "print('Saved label mappings to labels.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c953b6",
   "metadata": {},
   "source": [
    "## 4. Build and Compile MobileNetV2 Model\n",
    "Use TensorFlow/Keras to build a transfer learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24a7988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "preds = Dense(len(le.classes_), activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=preds)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c4775",
   "metadata": {},
   "source": [
    "## 5. Train and Evaluate Model\n",
    "Train the model and plot accuracy/loss curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4149fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0dcf42",
   "metadata": {},
   "source": [
    "## 5a. Evaluate Model on External Test Set\n",
    "Test model performance on a held-out dataset (e.g., Fitzpatrick17k test split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6061341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: External test evaluation\n",
    "fitz_test = fitz_meta.sample(frac=0.2, random_state=42)\n",
    "X_test = np.stack([load_and_preprocess(p) for p in fitz_test['img_path']])\n",
    "y_test = le.transform(fitz_test['dx'])\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print('External test loss, accuracy:', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce68019d",
   "metadata": {},
   "source": [
    "## 6. Export Trained Model\n",
    "Save the trained model as .h5 and TFLite formats for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e48f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as .h5\n",
    "model.save('mobilenetv2_skinologyke.h5')\n",
    "\n",
    "# Convert to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "with open('mobilenetv2_skinologyke.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5401847",
   "metadata": {},
   "source": [
    "## 6a. Upload Model to Hugging Face or Google Drive\n",
    "Share your trained model for deployment or collaboration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a43ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to Google Drive (requires Google Colab)\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "!cp mobilenetv2_skinologyke.h5 /content/drive/MyDrive/\n",
    "!cp mobilenetv2_skinologyke.tflite /content/drive/MyDrive/\n",
    "\n",
    "# Upload to Hugging Face (requires huggingface_hub)\n",
    "# !pip install huggingface_hub\n",
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"mobilenetv2_skinologyke.h5\",\n",
    "    path_in_repo=\"mobilenetv2_skinologyke.h5\",\n",
    "    repo_id=\"your-username/skinologyke-model\",\n",
    "    repo_type=\"model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99b315c",
   "metadata": {},
   "source": [
    "## 7. Next Steps\n",
    "- Test model on new images\n",
    "- Integrate with Flask API and Streamlit frontend\n",
    "- Document results and limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bac3130",
   "metadata": {},
   "source": [
    "# Production Integration & Expansion Roadmap\n",
    "This section outlines the steps to move each module from prototype to production, with actionable code and links to relevant files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf09c6ca",
   "metadata": {},
   "source": [
    "## 1. Before/After Gallery\n",
    "- Integrate uploads with Firebase Storage/Firestore (see `firebase_config.py`).\n",
    "- Build moderation dashboard and enforce consent.\n",
    "- Enable multi-user gallery viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baafe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Firebase Storage upload (Python)\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, storage, firestore\n",
    "cred = credentials.Certificate('path/to/serviceAccountKey.json')\n",
    "firebase_admin.initialize_app(cred, {'storageBucket': 'your-bucket.appspot.com'})\n",
    "\n",
    "def upload_image_to_firebase(image_path, user_id):\n",
    "    bucket = storage.bucket()\n",
    "    blob = bucket.blob(f'gallery/{user_id}/{os.path.basename(image_path)}')\n",
    "    blob.upload_from_filename(image_path)\n",
    "    # Save metadata to Firestore\n",
    "    db = firestore.client()\n",
    "    db.collection('gallery').add({'user_id': user_id, 'image_url': blob.public_url, 'approved': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c944057f",
   "metadata": {},
   "source": [
    "## 2. Shop Payments\n",
    "- Implement backend order tracking and inventory (see `api/endpoints/shop.py`).\n",
    "- Integrate MPESA API for payments.\n",
    "- Add order confirmation and receipts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e552d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: MPESA payment integration (pseudo-code)\n",
    "import requests\n",
    "mpesa_url = 'https://api.safaricom.co.ke/mpesa/stkpush/v1/processrequest'\n",
    "# ...prepare payload and headers...\n",
    "response = requests.post(mpesa_url, json=payload, headers=headers)\n",
    "if response.ok:\n",
    "    print('Payment initiated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865d9a74",
   "metadata": {},
   "source": [
    "## 3. Diagnosis API Integration\n",
    "- Deploy Flask API to Render/Fly.io with HTTPS (see `api/app.py`).\n",
    "- Add authentication and robust error handling.\n",
    "- Implement user feedback loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff45ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Deploy Flask API (Render)\n",
    "# 1. Add requirements.txt and render.yaml\n",
    "# 2. Push to GitHub and connect Render\n",
    "# 3. Set up HTTPS and environment variables\n",
    "# See deploy.md for details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8342cd24",
   "metadata": {},
   "source": [
    "## 4. Reminders & Routine Checklist\n",
    "- Integrate Formspree/Google Calendar for live reminders.\n",
    "- Sync routine checklist to backend for all users.\n",
    "- Complete OneSignal/browser notification integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33400984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Google Calendar API event creation (pseudo-code)\n",
    "from googleapiclient.discovery import build\n",
    "service = build('calendar', 'v3', credentials=creds)\n",
    "event = {\n",
    "    'summary': 'Skin Care Routine',\n",
    "    'start': {'dateTime': '2025-07-23T09:00:00', 'timeZone': 'Africa/Nairobi'},\n",
    "    'end': {'dateTime': '2025-07-23T09:30:00', 'timeZone': 'Africa/Nairobi'},\n",
    "}\n",
    "service.events().insert(calendarId='primary', body=event).execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89823b7",
   "metadata": {},
   "source": [
    "## 5. Authentication\n",
    "- Implement user profile, regimen/history saving (see `api/endpoints/auth.py`).\n",
    "- Integrate login with other modules for seamless experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526ed400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Save diagnosis result to user profile (pseudo-code)\n",
    "def save_diagnosis_to_profile(user_id, diagnosis):\n",
    "    db = firestore.client()\n",
    "    db.collection('users').document(user_id).update({'diagnosis_history': firestore.ArrayUnion([diagnosis])})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff1c12c",
   "metadata": {},
   "source": [
    "## 6. Blog\n",
    "- Deploy markdown posts to GitHub Pages/Notion/Ghost (see `blog_content/`).\n",
    "- Add SEO, images, and automate weekly posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b453f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Publish markdown to GitHub Pages (pseudo-code)\n",
    "# 1. Push markdown files to a GitHub repo\n",
    "# 2. Enable Pages in repo settings\n",
    "# 3. Use Jekyll or static site generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19dbada",
   "metadata": {},
   "source": [
    "## 7. Deployment & Hosting\n",
    "- Complete deployment to Render, Streamlit Cloud, Firebase Hosting.\n",
    "- Set up live URLs and SSL for API, frontend, and blog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2622776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Streamlit Cloud deployment\n",
    "# 1. Add requirements.txt\n",
    "# 2. Push to GitHub\n",
    "# 3. Deploy via Streamlit Cloud dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ac50c1",
   "metadata": {},
   "source": [
    "## 8. Expansion Features\n",
    "- Test and complete PWA/offline experience (see `public/manifest.json`, `public/service-worker.js`).\n",
    "- Implement skin tone detection, video consults, affiliate offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9606d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Skin tone detection (pseudo-code)\n",
    "def detect_skin_tone(image_path):\n",
    "    img = Image.open(image_path).resize((100, 100))\n",
    "    avg_color = np.mean(np.array(img), axis=(0, 1))\n",
    "    # ...map avg_color to skin tone category...\n",
    "    return avg_color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f60b9d",
   "metadata": {},
   "source": [
    "---\n",
    "For full implementation, see referenced files and update each module as described. Use this roadmap to track progress and add new cells/code as features are completed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76220e8",
   "metadata": {},
   "source": [
    "# Implementation Roadmap: Missing Features\n",
    "This section provides step-by-step code and instructions to implement all remaining MVP features for SkinologyKE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61535d7",
   "metadata": {},
   "source": [
    "## 1. AI Diagnostic Engine: Production API Deployment\n",
    "- Deploy Flask API to Render/Fly.io:\n",
    "    1. Add `requirements.txt` and `render.yaml` to `/api`.\n",
    "    2. Push to GitHub.\n",
    "    3. Create a new web service on Render/Fly.io, set environment variables, enable HTTPS.\n",
    "    4. Update `/frontend/js/diagnose.js` to call the live API endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b4e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload trained model to Hugging Face Hub\n",
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"mobilenetv2_skinologyke.h5\",\n",
    "    path_in_repo=\"mobilenetv2_skinologyke.h5\",\n",
    "    repo_id=\"your-username/skinologyke-model\",\n",
    "    repo_type=\"model\"\n",
    ")\n",
    "print(\"Model uploaded to Hugging Face.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca60a1",
   "metadata": {},
   "source": [
    "## AI Diagnostic Engine: Frontend Integration\n",
    "- In `/frontend/diagnose.html` and `/frontend/js/diagnose.js`, connect the upload form to the Flask API endpoint and display diagnosis results.\n",
    "- In `/streamlit_app/main.py`, update to call the deployed API for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6da85b",
   "metadata": {},
   "source": [
    "## AI Diagnostic Engine: Referral Workflow\n",
    "- Add WhatsApp deep link: `<a href='https://wa.me/254700000000?text=I+need+a+dermatologist+referral+for+my+SkinologyKE+diagnosis'>Contact Dermatologist</a>`\n",
    "- Add Google Forms link: `<a href='https://forms.gle/your-google-form-id'>Referral Form</a>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ecc4b",
   "metadata": {},
   "source": [
    "## 2. Dermatology Blog: Public Deployment & Automation\n",
    "- Publish markdown posts to GitHub Pages:\n",
    "    1. Push `/blog_content/*.md` to a GitHub repo.\n",
    "    2. Enable Pages in repo settings.\n",
    "    3. Use Jekyll for static site generation.\n",
    "- Automate SEO meta tags and image formatting in blog markdown files.\n",
    "- Set up GitHub Actions for weekly post automation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4b9357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Add SEO meta tags to markdown\n",
    "for md_file in [\"acne-tips.md\", \"skin-lightening-risks.md\", \"eczema-vs-fungal.md\", \"pigmentation-facts.md\"]:\n",
    "    with open(f\"../blog_content/{md_file}\", \"r+\") as f:\n",
    "        content = f.read()\n",
    "        seo = f\"<!-- SEO: Published 2025-07-22 -->\\n\"\n",
    "        f.seek(0, 0)\n",
    "        f.write(seo + content)\n",
    "print(\"SEO meta tags added.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e12f917",
   "metadata": {},
   "source": [
    "## 3. Skin Routine Checklist & Reminder Tool\n",
    "- Integrate Google Calendar API and Formspree/Zapier for reminders.\n",
    "- Set up OneSignal/browser push notifications in `/frontend/js/reminders.js`.\n",
    "- Ensure backend sync of routine data for all users via Firestore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c8839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Google Calendar event creation\n",
    "from googleapiclient.discovery import build\n",
    "service = build('calendar', 'v3', credentials=creds)\n",
    "event = {\n",
    "    'summary': 'Skin Care Routine',\n",
    "    'start': {'dateTime': '2025-07-23T09:00:00', 'timeZone': 'Africa/Nairobi'},\n",
    "    'end': {'dateTime': '2025-07-23T09:30:00', 'timeZone': 'Africa/Nairobi'},\n",
    "}\n",
    "service.events().insert(calendarId='primary', body=event).execute()\n",
    "print(\"Routine reminder added to Google Calendar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad18ed57",
   "metadata": {},
   "source": [
    "## 4. Shop Module: Backend, Payments, Order Tracking\n",
    "- Add product database and inventory management in Firestore (`/api/endpoints/shop.py`).\n",
    "- Integrate Flutterwave/Paystack/MPESA payment API in backend and frontend.\n",
    "- Implement order tracking and receipts in backend and `/frontend/shop.html`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64738673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Add product to Firestore\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore\n",
    "cred = credentials.Certificate('path/to/serviceAccountKey.json')\n",
    "firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "db.collection('products').add({\n",
    "    'name': 'Cerave Cleanser',\n",
    "    'price': 1200,\n",
    "    'stock': 10,\n",
    "    'skin_type': 'Oily',\n",
    "    'ingredients': ['Ceramides', 'Niacinamide']\n",
    "})\n",
    "print(\"Product added to Firestore.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3c27c8",
   "metadata": {},
   "source": [
    "## 5. Referral System: WhatsApp & Google Forms\n",
    "- Add WhatsApp deep link and Google Forms to `/frontend/diagnose.html` and `/streamlit_app/main.py`.\n",
    "- Set up dermatologist panel and email routing in backend (`/api/endpoints/referral.py`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed21a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Send referral email (pseudo-code)\n",
    "def send_referral_email(user_email, diagnosis):\n",
    "    # Use SMTP or email API\n",
    "    # ...existing code...\n",
    "    print(f\"Referral sent for {user_email} with diagnosis: {diagnosis}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bbcf6c",
   "metadata": {},
   "source": [
    "## 6. Before/After Gallery: Firebase Integration & Moderation\n",
    "- Connect gallery uploads to Firebase Storage/Firestore in `/frontend/js/firebase_init.js` and `/api/firebase_config.py`.\n",
    "- Build admin dashboard for moderation in `/frontend/gallery.html`.\n",
    "- Enable multi-user gallery viewing in frontend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Approve gallery image in Firestore\n",
    "image_id = 'abc123'\n",
    "db.collection('gallery').document(image_id).update({'approved': True})\n",
    "print(\"Gallery image approved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b64b2e",
   "metadata": {},
   "source": [
    "## 7. Platform Architecture & Deployment\n",
    "- Set up live URLs for API, frontend, and blog in `deploy.md`.\n",
    "- Configure custom domain and SSL in Firebase/Render settings.\n",
    "- Test PWA/offline experience using `public/manifest.json` and `public/service-worker.js`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72602367",
   "metadata": {},
   "source": [
    "## 8. Expansion Options: Skin Tone, Video Consults, Affiliate Offers\n",
    "- Implement skin tone detection in `/ai_model/export_model.py` and frontend.\n",
    "- Add video consults via Jitsi/Zoom in `/frontend/pages/Consult.tsx`.\n",
    "- Add affiliate offers in `/frontend/shop.html` and backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa962c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Skin tone detection\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "def detect_skin_tone(image_path):\n",
    "    img = Image.open(image_path).resize((100, 100))\n",
    "    avg_color = np.mean(np.array(img), axis=(0, 1))\n",
    "    # Map avg_color to skin tone category\n",
    "    return avg_color\n",
    "print(\"Skin tone detected.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
